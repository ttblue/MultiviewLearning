{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information import failed.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Tests for some CCA stuff on pig data.\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dataprocessing import predictive_maintenance_datasets\n",
    "from models import \\\n",
    "    embeddings, greedy_multi_view_rl, greedy_single_view_rl,\\\n",
    "    naive_multi_view_rl, naive_single_view_rl, ovr_mcca_embeddings,\\\n",
    "    robust_multi_ae, torch_models, ts_fourier_featurization\n",
    "from synthetic import multimodal_systems as ms\n",
    "from tests.test_greedy_mvrl import default_GMVRL_config\n",
    "from tests.test_mv_pig_data import \\\n",
    "    plot_heatmap, default_NGSRL_config, default_RMAE_config,\\\n",
    "    aggregate_multipig_data, rescale, split_data, make_subset_list, error_func,\\\n",
    "    all_subset_accuracy\n",
    "from utils import torch_utils, utils, time_series_utils\n",
    "\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  MPL_AVAILABLE = True\n",
    "except ImportError:\n",
    "  MPL_AVAILABLE = False\n",
    "\n",
    "\n",
    "import IPython\n",
    "\n",
    "\n",
    "# Plotting funcs:\n",
    "def plot_windows(\n",
    "    tvals, labels, ndisp, title, nwin, wsize, ax=None, shuffle=True):\n",
    "  plot_ts = []\n",
    "  for win in tvals:\n",
    "    plot_ts.append(win.reshape(-1, win.shape[-1]))\n",
    "\n",
    "  if nwin is not None and nwin > 0:\n",
    "    ndisp = nwin * wsize\n",
    "\n",
    "  if shuffle and ndisp > 0:\n",
    "    IPython.embed()\n",
    "    shuffle_inds = [np.random.permutation(p.shape[0])[:ndisp] for p in plot_ts]\n",
    "    plot_ts = [win[inds] for win, inds in zip(plot_ts, shuffle_inds)]\n",
    "\n",
    "  if ndisp > 0:\n",
    "    plot_ts = [win[:ndisp] for win in plot_ts]\n",
    "\n",
    "  ntsteps = plot_ts[0].shape[0]\n",
    "\n",
    "  ax = plt if ax is None else ax\n",
    "\n",
    "  for win, lbl in zip(plot_ts, labels):\n",
    "    ax.plot(win, label=lbl)\n",
    "  # ax.plot(tv_plot, color='b', label=\"Ground Truth\")\n",
    "  # ax.plot(op_plot, color='r', label=\"Predicted\")\n",
    "  if title:\n",
    "    try:\n",
    "      ax.title(title, fontsize=30)\n",
    "      ax.xticks(fontsize=15)\n",
    "      ax.yticks(fontsize=15)\n",
    "      ax.legend(fontsize=15)\n",
    "    except TypeError:\n",
    "      ax.set_title(title, fontsize=10)\n",
    "      ax.legend()\n",
    "      # ax.set_xticks(fontsize=5)\n",
    "      # ax.set_yticks(fontsize=5)\n",
    "    # if nwin is not None and nwin > 0:\n",
    "\n",
    "  win_x = wsize\n",
    "  while win_x < ntsteps:\n",
    "    ax.axvline(x = win_x, ls=\"--\")\n",
    "    win_x += wsize\n",
    "\n",
    "\n",
    "def split_into_windows(data, window_size, shuffle=True):\n",
    "  ids, ts, feats, ys = data[\"ids\"], data[\"ts\"], data[\"features\"], data[\"y\"]\n",
    "\n",
    "  window_data = {key: [] for key in data}\n",
    "  # Go over the t-series of each unit\n",
    "  idx = 0\n",
    "  for u_id, u_ts, u_ft, u_y in zip(ids, ts, feats, ys):\n",
    "    if u_ft.shape[0] < window_size:\n",
    "      print(\"Skipping %s. Not enough data for a window.\" % (u_id,))\n",
    "      continue\n",
    "    u_ts_ft = np.c_[u_ts.reshape(-1, 1), u_ft]\n",
    "    try:\n",
    "      w_ts_ft = time_series_utils.split_ts_into_windows(\n",
    "          u_ts_ft, window_size, ignore_rest=False, shuffle=shuffle)\n",
    "    except Exception as e:\n",
    "      IPython.embed()\n",
    "      raise e\n",
    "    idx += 1\n",
    "    w_ts, w_ft = w_ts_ft[:, :, 0], w_ts_ft[:, :, 1:]\n",
    "    n_win = w_ft.shape[0]\n",
    "    w_ids = [u_id] * n_win\n",
    "    w_ys = [u_y] * n_win\n",
    "\n",
    "    window_data[\"ids\"].extend(w_ids)\n",
    "    window_data[\"y\"].extend(w_ys)\n",
    "    window_data[\"ts\"].append(w_ts)\n",
    "    window_data[\"features\"].append(w_ft)\n",
    "\n",
    "  for key in [\"ts\", \"features\"]:\n",
    "    window_data[key] = np.concatenate(window_data[key], axis=0)\n",
    "\n",
    "  return window_data\n",
    "\n",
    "\n",
    "_FFT_DIM = 30\n",
    "_FFT_MODEL = None\n",
    "_CH_MODELS = None\n",
    "# Featurization depends only on training data. So this should be called first\n",
    "# on training data.\n",
    "def fft_featurize_data(window_data):\n",
    "  global _FFT_MODEL, _CH_MODELS\n",
    "\n",
    "  ts, feat = window_data[\"ts\"], window_data[\"features\"]\n",
    "  window_size = feat.shape[1]\n",
    "\n",
    "  if _FFT_MODEL is None:\n",
    "    fft_model_file = os.path.join(\n",
    "        os.getenv(\"RESEARCH_DIR\"), \"tests/saved_models\",\n",
    "        \"cmas_fft_feats_ws%i.fart\" % window_size)\n",
    "    config = ts_fourier_featurization.FFConfig(\n",
    "        ndim=_FFT_DIM, use_imag=False, verbose=True)\n",
    "    _FFT_MODEL = ts_fourier_featurization.TimeSeriesFourierFeaturizer(config)\n",
    "    if os.path.exists(fft_model_file):\n",
    "      print(\"Loading fft model.\")\n",
    "      _FFT_MODEL.load_from_file(fft_model_file)\n",
    "      _FFT_MODEL.config.ndim = _FFT_DIM\n",
    "    else:\n",
    "      print(\"Training and saving fft model.\")\n",
    "      _FFT_MODEL.fit(feat, ts)\n",
    "      _FFT_MODEL.save_to_file(fft_model_file)\n",
    "\n",
    "    _CH_MODELS = _FFT_MODEL.split_channels_into_models()\n",
    "\n",
    "  mv_data = {}\n",
    "  for i, ch_model in enumerate(_CH_MODELS):\n",
    "    ch_windows = feat[:, :, [i]]\n",
    "    mv_data[i] = np.squeeze(ch_model.encode(ch_windows))\n",
    "\n",
    "  return mv_data\n",
    "\n",
    "\n",
    "def load_cmas_data(window_size=20):\n",
    "  normalize = True\n",
    "  dset_type = \"all\"\n",
    "  data, misc = predictive_maintenance_datasets.load_cmas(dset_type, normalize)\n",
    "\n",
    "  # Just need to make sure fft feats are done on train data first.\n",
    "  window_data = {}\n",
    "  fft_window_data = {}\n",
    "  for dset_type in [\"train\", \"test\"]:\n",
    "    wdata = split_into_windows(data[dset_type], window_size)\n",
    "    fft_window_data[dset_type] = fft_featurize_data(wdata)\n",
    "    window_data[dset_type] = wdata\n",
    "\n",
    "  return window_data, fft_window_data\n",
    "\n",
    "\n",
    "def reconstruct_ts(codes, output_len):\n",
    "  output_ts = {}\n",
    "  for k, ch_code in codes.items():\n",
    "    output_ts[k] = _CH_MODELS[k].decode(ch_code, output_len)\n",
    "\n",
    "  return output_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "  etype = 1\n",
    "  wsize = 20\n",
    "  npts = 1000\n",
    "  njobs = 3\n",
    "  max_iters = 250\n",
    "  num_ss_tfm = 1\n",
    "  num_lin_tfm = 1\n",
    "  use_leaky_relu = False\n",
    "  use_reverse = False\n",
    "  dist_type = \"gaussian\"\n",
    "  use_ar = False\n",
    "  n_components = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fft model.\n",
      "Skipping (4, 141). Not enough data for a window.\n",
      "Skipping (4, 204). Not enough data for a window.\n"
     ]
    }
   ],
   "source": [
    "window_size = args.wsize\n",
    "npts = args.npts\n",
    "win_data, cmas_data = load_cmas_data(window_size=window_size)\n",
    "\n",
    "# Fit model.\n",
    "tr_w_ffts = cmas_data[\"train\"]\n",
    "te_w_ffts = cmas_data[\"test\"]\n",
    "tr_wdata = win_data[\"train\"][\"features\"]\n",
    "te_wdata = win_data[\"test\"][\"features\"]\n",
    "\n",
    "dsets = {\"Train\": tr_wdata, \"Test\": te_wdata}\n",
    "\n",
    "config = default_NGSRL_config(sv_type=\"nn\")\n",
    "config.njobs = None if args.njobs == -1 else args.njobs\n",
    "if npts > 0:\n",
    "  tr_w_ffts = {vi: d[:npts] for vi, d in tr_w_ffts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.single_view_config.lambda_global = 1e-3\n",
    "config.single_view_config.lambda_group = 0 # 1e-1\n",
    "config.single_view_config.sp_eps = 5e-5\n",
    "config.single_view_config.max_iters = args.max_iters\n",
    "\n",
    "model = naive_multi_view_rl.NaiveBlockSparseMVRL(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for group sparse transforms.\n",
      "  Solving problems in parallel...\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.Starting training loop.\n",
      "\n",
      "\n",
      "Iteration 1 out of 1.Starting training loop.\n",
      "\n",
      "\n",
      "Iteration 1 out of 1.Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.Starting training loop.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.Starting training loop.\n",
      "\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Loss: 1107.98779\n",
      "Loss: 161.60947\n",
      "Iteration 1 took 4.58s.\n",
      "Iteration 1 took 4.55s.\n",
      "Training finished in 4.74 s.\n",
      "Training finished in 4.74 s.\n",
      "Loss: 980.89722\n",
      "Iteration 1 took 4.88s.\n",
      "Training finished in 4.98 s.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.\n",
      "Starting training loop.\n",
      "\n",
      "Iteration 1 out of 1.Loss: 1133.92261\n",
      "\n",
      "Iteration 1 took 5.34s.\n",
      "Training finished in 5.55 s.\n",
      "Loss: 705.90991\n",
      "Starting training loop.\n",
      "Iteration 1 took 5.53s.\n",
      "\n",
      "Iteration 1 out of 1.Training finished in 5.72 s.\n",
      "\n",
      "Loss: 1050.00342\n",
      "Iteration 1 took 5.80s.\n",
      "Loss: 821.95721\n",
      "Training finished in 5.94 s.\n",
      "Iteration 1 took 5.72s.\n",
      "Starting training loop.\n",
      "Loss: 1081.88440\n",
      "\n",
      "Iteration 1 out of 1.Training finished in 5.92 s.\n",
      "Iteration 1 took 5.98s.\n",
      "\n",
      "Loss: 974.57227\n",
      "Training finished in 6.13 s.\n",
      "Iteration 1 took 5.77s.\n",
      "Training finished in 5.92 s.\n",
      "Loss: 761.26154\n",
      "Loss: 934.79071\n",
      "Iteration 1 took 6.01s.\n",
      "Iteration 1 took 5.81s.\n",
      "Training finished in 6.00 s.\n",
      "Training finished in 6.16 s.\n",
      "Loss: 999.25000\n",
      "Iteration 1 took 5.86s.\n",
      "Training finished in 6.03 s.\n",
      "Loss: 761.46710\n",
      "Loss: 742.09253\n",
      "Iteration 1 took 6.20s.\n",
      "Training finished in 6.31 s.\n",
      "Iteration 1 took 6.44s.\n",
      "Loss: 1142.67651\n",
      "Training finished in 6.55 s.\n",
      "Iteration 1 took 5.95s.\n",
      "Training finished in 6.16 s.\n",
      "Loss: 338.15311\n",
      "Iteration 1 took 6.51s.\n",
      "Training finished in 6.65 s.\n",
      "Loss: 852.85522\n",
      "Iteration 1 took 5.95s.\n",
      "Training finished in 6.07 s.\n",
      "Loss: 762.39178\n",
      "Iteration 1 took 6.24s.\n",
      "Training finished in 6.40 s.\n",
      "Loss: 730.96863\n",
      "Iteration 1 took 6.69s.\n",
      "Training finished in 6.79 s.\n",
      "Loss: 785.25391\n",
      "Iteration 1 took 5.89s.\n",
      "Training finished in 5.98 s.\n",
      "Loss: 322.26324\n",
      "Iteration 1 took 3.60s.\n",
      "Training finished in 3.73 s.\n",
      "Loss: 105.76987\n",
      "Iteration 1 took 3.54s.\n",
      "Training finished in 3.60 s.\n",
      "Loss: 1066.17810\n",
      "Iteration 1 took 3.28s.\n",
      "Training finished in 3.34 s.\n",
      "Loss: 984.88538\n",
      "Iteration 1 took 3.13s.\n",
      "Training finished in 3.21 s.\n",
      "Python 3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 7.4.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n",
      "In [1]: e\n",
      "Out[1]: FileNotFoundError(2, 'No such file or directory')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  model.config.single_view_config.max_iters = 1\n",
    "  model.fit(tr_w_ffts)\n",
    "except Exception as e:\n",
    "  IPython.embed()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._trained = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model._trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NaiveBlockSparseMVRL' object has no attribute '_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5770dbfff7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NaiveBlockSparseMVRL' object has no attribute '_x'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
