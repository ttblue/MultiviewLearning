{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "from sklearn import manifold\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from models import flow_transforms, flow_likelihood#, flow_pipeline\n",
    "from models import torch_models\n",
    "from synthetic import flow_toy_data\n",
    "from utils import utils, torch_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "\n",
    "def default_nn_config():\n",
    "  input_size = 10  # Computed online\n",
    "  output_size = 10  # Computed online\n",
    "  layer_units = [32, 64]\n",
    "  use_vae = False\n",
    "  activation = nn.ReLU  # nn.functional.relu\n",
    "  last_activation = torch_models.Identity  # functional.sigmoid\n",
    "  # layer_types = None\n",
    "  # layer_args = None\n",
    "  bias = True\n",
    "  dropout_p = 0.\n",
    "  layer_types, layer_args = torch_utils.generate_linear_types_args(\n",
    "        input_size, layer_units, output_size, bias)\n",
    "  nn_config = torch_models.MNNConfig(\n",
    "      input_size=input_size, output_size=output_size, layer_types=layer_types,\n",
    "      layer_args=layer_args, activation=activation,\n",
    "      last_activation=last_activation, dropout_p=dropout_p, use_vae=use_vae)\n",
    "  return nn_config\n",
    "\n",
    "\n",
    "def default_tfm_config(tfm_type=\"shift_scale_coupling\"):\n",
    "  neg_slope = 0.1\n",
    "  scale_config = default_nn_config()\n",
    "  scale_config.last_activation = torch.nn.Tanh\n",
    "  shift_config = default_nn_config()\n",
    "  shift_config.last_activation = torch.nn.Sigmoid\n",
    "  shared_wts = False\n",
    "\n",
    "  ltfm_config = default_nn_config()\n",
    "  bias_config = default_nn_config()\n",
    "\n",
    "  has_bias = True\n",
    "\n",
    "  base_dist = \"gaussian\"\n",
    "  reg_coeff = 0.\n",
    "  lr = 1e-3\n",
    "  batch_size = 50\n",
    "  max_iters = 1000\n",
    "\n",
    "  stopping_eps = 1e-5\n",
    "  num_stopping_iter = 1000\n",
    "\n",
    "  grad_clip = 2.\n",
    "\n",
    "  verbose = True\n",
    "\n",
    "  config = flow_transforms.TfmConfig(\n",
    "      tfm_type=tfm_type, neg_slope=neg_slope, scale_config=scale_config,\n",
    "      shift_config=shift_config, shared_wts=shared_wts, ltfm_config=ltfm_config,\n",
    "      bias_config=bias_config, has_bias=has_bias, reg_coeff=reg_coeff,\n",
    "      base_dist=base_dist, lr=lr, batch_size=batch_size, max_iters=max_iters,\n",
    "      stopping_eps=stopping_eps, num_stopping_iter=num_stopping_iter,\n",
    "      grad_clip=grad_clip, verbose=verbose)\n",
    "  return config\n",
    "\n",
    "\n",
    "def default_likelihood_config(args):\n",
    "  model_type = \"linear_arm\"\n",
    "  n_components = args.n_components\n",
    "  dist_type = args.dist_type\n",
    "\n",
    "  hidden_size = 32\n",
    "  theta_nn_config = default_nn_config()\n",
    "  theta_nn_config.last_activation = torch.nn.Tanh\n",
    "  cell_type = \"LSTM\"  # not needed for linear_arm\n",
    "\n",
    "  verbose = True\n",
    "\n",
    "  config = flow_likelihood.ARMMConfig(\n",
    "      model_type=model_type, dist_type=dist_type, n_components=n_components,\n",
    "      hidden_size=hidden_size, theta_nn_config=theta_nn_config,\n",
    "      cell_type=cell_type, verbose=verbose)\n",
    "\n",
    "  return config\n",
    "\n",
    "\n",
    "def default_pipeline_config():\n",
    "  pass\n",
    "\n",
    "\n",
    "def make_default_data(args, split=False):\n",
    "  tfm_types = [ \"linear\"]\n",
    "  if args.dtype == \"single_dim_copy\":\n",
    "    Z = np.concatenate([np.random.randn(args.npts, 1)] * args.ndim, axis=1)\n",
    "    scale = 5.\n",
    "    scale_mat = np.eye(args.ndim) * scale\n",
    "    X = Z.dot(scale_mat)\n",
    "    tfm_args = []\n",
    "  else:\n",
    "    Z, X, tfm_args = flow_toy_data.simple_transform_data(\n",
    "        args.npts, args.ndim, tfm_types)\n",
    "\n",
    "  if split:\n",
    "    split_frac = [0.8, 0.2]\n",
    "    (tr_Z, te_Z), inds = utils.split_data(Z, split_frac, get_inds=True)\n",
    "    tr_X, te_X = [X[idx] for idx in inds]\n",
    "\n",
    "    return (tr_Z, te_Z), (tr_X, te_X), tfm_args\n",
    "  return Z, X, tfm_args\n",
    "\n",
    "\n",
    "def make_default_data_X(args, split=False, normalize_scale=None):\n",
    "  # Z, X, tfm_args = flow_toy_data.simple_transform_data(\n",
    "  #     args.npts, args.ndim, tfm_types)  \n",
    "  X = np.random.randn(args.npts, args.ndim)\n",
    "  if normalize_scale is not None:\n",
    "    X_norm = np.linalg.norm(X, axis=1).reshape(-1, 1)\n",
    "    X = X / X_norm * normalize_scale\n",
    "\n",
    "  if split:\n",
    "    split_frac = [0.8, 0.2]\n",
    "    tr_X, te_X = utils.split_data(X, split_frac, get_inds=False)\n",
    "    return tr_X, te_X\n",
    "  return X\n",
    "\n",
    "\n",
    "def make_default_tfm(args, tfm_args=[]):\n",
    "  dim = args.ndim\n",
    "  num_ss_tfm = args.num_ss_tfm\n",
    "  num_lin_tfm = args.num_lin_tfm\n",
    "  use_leaky_relu = args.use_leaky_relu\n",
    "  use_reverse = args.use_reverse\n",
    "\n",
    "  # Generate config list:\n",
    "  tfm_configs = []\n",
    "  tfm_inits = []\n",
    "\n",
    "  #################################################\n",
    "  # Bit-mask couple transform\n",
    "  tfm_idx = 0\n",
    "  idx_args = tfm_args[tfm_idx] if tfm_idx < len(tfm_args) else None\n",
    "  if idx_args is not None and idx_args[0] == \"scaleshift\":\n",
    "    bit_mask = idx_args[1]\n",
    "\n",
    "  for i in range(num_ss_tfm):\n",
    "    scale_shift_tfm_config = default_tfm_config(\"scale_shift_coupling\")\n",
    "    tfm_configs.append(scale_shift_tfm_config)\n",
    "    if idx_args is not None and idx_args[0] == \"scaleshift\":\n",
    "      bit_mask = 1 - bit_mask\n",
    "    else:\n",
    "      bit_mask = np.zeros(dim)\n",
    "      bit_mask[np.random.permutation(dim)[:dim//2]] = 1\n",
    "    tfm_inits.append((bit_mask,))\n",
    "\n",
    "  # Fixed linear transform\n",
    "  tfm_idx = 1\n",
    "  # L, U = tfm_args[tfm_idx][1:]\n",
    "  # _, Li, Ui = scipy.linalg.lu(np.linalg.inv(L.dot(U)))\n",
    "  # init_mat = np.tril(Li, -1) + np.triu(Ui, 0)\n",
    "  # eps = 1e-1\n",
    "  # noise = np.random.randn(*init_mat.shape) * eps\n",
    "  for i in range(num_lin_tfm):\n",
    "    linear_tfm_config = default_tfm_config(\"fixed_linear\")\n",
    "    linear_tfm_config.has_bias = False\n",
    "    tfm_configs.append(linear_tfm_config)\n",
    "    tfm_inits.append((dim,))# init_mat))\n",
    "\n",
    "  # # Leaky ReLU\n",
    "  tfm_idx = 2\n",
    "  if use_leaky_relu:\n",
    "    leaky_relu_config = default_tfm_config(\"leaky_relu\")\n",
    "    leaky_relu_config.neg_slope = 0.1\n",
    "    tfm_configs.append(leaky_relu_config)\n",
    "    tfm_inits.append(None)\n",
    "\n",
    "  # Reverse\n",
    "  tfm_idx = 3\n",
    "  if use_reverse:\n",
    "    reverse_config = default_tfm_config(\"reverse\")\n",
    "    tfm_configs.append(reverse_config)\n",
    "    tfm_inits.append(None)\n",
    "  #################################################\n",
    "  comp_config = default_tfm_config(\"composition\")\n",
    "  model = flow_transforms.make_transform(tfm_configs, tfm_inits, comp_config)\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "def make_default_likelihood_model(args):\n",
    "  if not args.use_ar:\n",
    "    return None\n",
    "  config = default_likelihood_config(args)\n",
    "  model = flow_likelihood.make_likelihood_model(config)\n",
    "  model.initialize(args.ndim)\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "  etype = 1\n",
    "  dtype = 1\n",
    "  npts = 1000\n",
    "  ndim = 10\n",
    "  max_iters = 50000\n",
    "  num_ss_tfm = 1\n",
    "  num_lin_tfm = 1\n",
    "  use_leaky_relu = False\n",
    "  use_reverse = False\n",
    "  dist_type = \"gaussian\"\n",
    "  use_ar = False\n",
    "  n_components = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (tr_Z, te_Z), (tr_X, te_X), tfm_args = make_default_data(\n",
    "#     args, split=True, normalize_scale=5)\n",
    "nscale = 50.\n",
    "tr_X, te_X = make_default_data_X(args, split=True, normalize_scale=nscale)\n",
    "model = make_default_tfm(args, tfm_args=[])\n",
    "lhood_model = make_default_likelihood_model(args)\n",
    "\n",
    "config = model.config\n",
    "config.batch_size = 1000\n",
    "config.lr = 1e-4\n",
    "config.reg_coeff = 0.1\n",
    "config.max_iters = args.max_iters\n",
    "config.stopping_eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50000 out of 50000 (in 0.01s). Loss: 41.49175. Avg grad: 0.00005.Stop iter: 02. Stop iter: 0200\n",
      "Training finished in 305.30 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompositionTransform(\n",
       "  (_tfm_list): ModuleList(\n",
       "    (0): ScaleShiftCouplingTransform(\n",
       "      (_scale_tfm): MultiLayerNN(\n",
       "        (dropout): Dropout(p=0.0)\n",
       "        (_logvar): Zeros()\n",
       "        (_layer_op): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (_mu): Linear(in_features=64, out_features=5, bias=True)\n",
       "        (_last_activation): Tanh()\n",
       "      )\n",
       "      (_shift_tfm): MultiLayerNN(\n",
       "        (dropout): Dropout(p=0.0)\n",
       "        (_logvar): Zeros()\n",
       "        (_layer_op): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (_mu): Linear(in_features=64, out_features=5, bias=True)\n",
       "        (_last_activation): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (1): FixedLinearTransformation()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tr_X, lhood_model=lhood_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_Z_pred = model(tr_X, False, False)\n",
    "te_Z_pred = model(te_X, False, False)\n",
    "tr_Zinv_pred = model.inverse(tr_Z_pred, False)\n",
    "te_Zinv_pred = model.inverse(te_Z_pred, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_samples = args.npts // 2\n",
    "samples = model.sample(n_test_samples, inverted=False, rtn_torch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 7.4.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n",
      "In [1]: exit()\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 1: B should have 1 or 2 dimensions, but has 3 at /opt/conda/conda-bld/pytorch-cpu_1549632688322/work/aten/src/TH/generic/THTensorLapack.cpp:155",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4641c37aba37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# samples = np.concatenate(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     [np.random.randn(n_test_samples, 1)] * args.ndim, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtn_torch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/TransferLearning/TS/python/models/flow_transforms.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, y, rtn_torch)\u001b[0m\n\u001b[1;32m    514\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrtn_torch\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/TransferLearning/TS/python/models/flow_transforms.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, y, rtn_torch)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfm_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/TransferLearning/TS/python/models/flow_transforms.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, y, rtn_torch)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;31m# Torch solver for triangular system of equations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# IPython.embed()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0msol_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrtrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_b_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munitriangular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrtrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol_L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# trtrs always returns 2-D output, even if input is 1-D. So we do this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 1: B should have 1 or 2 dimensions, but has 3 at /opt/conda/conda-bld/pytorch-cpu_1549632688322/work/aten/src/TH/generic/THTensorLapack.cpp:155"
     ]
    }
   ],
   "source": [
    "# samples = np.concatenate(\n",
    "#     [np.random.randn(n_test_samples, 1)] * args.ndim, axis=1)\n",
    "X_samples = model.inverse(samples, rtn_torch=False)\n",
    "X_all = np.r_[tr_X, te_X, X_samples]\n",
    "Z_all = np.r_[tr_Z_pred, te_Z_pred, samples]\n",
    "Zinv_all = np.r_[tr_Zinv_pred, te_Zinv_pred, X_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(2)\n",
    "y_x = tsne.fit_transform(X_all)\n",
    "y_z = tsne.fit_transform(Z_all)\n",
    "y_zi = tsne.fit_transform(Zinv_all)\n",
    "plot_data = {\"x\": y_x, \"z\": y_z, \"zi\": y_zi}\n",
    "pdtype = \"z\"\n",
    "y = plot_data[pdtype]\n",
    "\n",
    "plt.scatter(y[:args.npts, 0], y[:args.npts, 1], color=\"b\")\n",
    "plt.scatter(y[args.npts:, 0], y[args.npts:, 1], color=\"r\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(y[:tr_X.shape[0], 0], y[:tr_X.shape[0], 1], color=\"b\")\n",
    "plt.scatter(y[tr_X.shape[0]:args.npts, 0], y[tr_X.shape[0]:args.npts, 1], color=\"r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
